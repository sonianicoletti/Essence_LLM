Report: Context Filtering Strategies in Essence Coach

1. Objective

The goal of this task was to improve the relevance of context snippets retrieved for answering user queries in the Essence Coach application.
We implemented a filtering stage after the ensemble retrieval process to reduce irrelevant context and enhance the quality of the chatbot's responses.

2. Filtering Strategies

We implemented and tested the following strategies:
- No Filtering (baseline)
- Cosine Similarity Filtering (threshold: 0.75)
- LLM-based Filtering (using Groq API with Llama3-8b-8192)

3. Evaluation Metrics

We calculated standard retrieval metrics including Precision@K, MRR, and MAP. Table summarizes the results in file retrieval_filtering_metrics.

4. Qualitative Examples

We analyzed retrieved contexts across 10 representative queries. Here are three example comparisons (in JSON format):
- See `results_nofilter.json` for baseline (no filtering).
- See `results_cosine075.json` for cosine similarity filtering.
- See `results_llm.json` for LLM-based filtering.

5. Conclusions

Filtering strategies, especially LLM-based filtering, significantly reduced the amount of irrelevant context passed to the model.
This led to better precision in responses and leaner context windows. Cosine filtering with threshold also performed reasonably well.